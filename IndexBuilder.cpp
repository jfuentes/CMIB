/**
***
*** Copyright  (C) 1985-2011 Intel Corporation. All rights reserved.
***
*** The information and source code contained herein is the exclusive
*** property of Intel Corporation. and may not be disclosed, examined
*** or reproduced in whole or in part without explicit written authorization
*** from the company.
***
*** ----------------------------------------------------------------------------
**/


#include "cm_rt.h"

//#include "../../compiler/include/cm/cm_vm.h"

#include <time.h>
#include <vector>
#include <bitset>
#include <algorithm>
#include <math.h>
#include "K2tree.h"
#include "radix.h"

// Includes bitmap_helpers.h for bitmap file open/save/compare operations.
#include "bitmap_helpers.h"

// Include cm_rt_helpers.h to convert the integer return code returned from
// the CM runtime to a meaningful string message.
#include "cm_rt_helpers.h"

// Includes isa_helpers.h to load the ISA file generated by the CM compiler.
#include "isa_helpers.h"

using namespace std;

void cmk_bits_test();
void cmk_last_levels_construction(SurfaceIndex matrix_in, SurfaceIndex L_out, SurfaceIndex T_out, UINT total_threads, UINT x, UINT y);
void cmk_mid_levels_construction(SurfaceIndex matrix_in, SurfaceIndex T_out, UINT total_threads, UINT x, UINT y);
void cmk_generate_morton_numbers(SurfaceIndex input, SurfaceIndex output);

void bitsTest() {
  // Creates a CmDevice from scratch.
  // Param device: pointer to the CmDevice object.
  // Param version: CM API version supported by the runtime library.
  CmDevice *device = nullptr;
  unsigned int version = 0;
  cm_result_check(::CreateCmDevice(device, version));
  // The file linear_walker_genx.isa is generated when the kernels in the file
  // linear_walker_genx.cpp are compiled by the CM compiler.
  // Reads in the virtual ISA from "K2tree_genx.isa" to the code
  // buffer.
  std::string isa_code = cm::util::isa::loadFile("IndexBuilder_genx.isa");
  if (isa_code.size() == 0) {
    std::cout << "Error: empty ISA binary.\n";
    exit(1);
  }

  // Creates a CmProgram object consisting of the kernels loaded from the code
  // buffer.
  // Param isa_code.data(): Pointer to the code buffer containing the virtual
  // ISA.
  // Param isa_code.size(): Size in bytes of the code buffer containing the
  // virtual ISA.
  CmProgram *program = nullptr;
  cm_result_check(device->LoadProgram(const_cast<char*>(isa_code.data()),
    isa_code.size(),
    program));

  CmKernel *bits_test_kernel = nullptr;
  cm_result_check(device->CreateKernel(program,
    CM_KERNEL_FUNCTION(cmk_bits_test),
    bits_test_kernel));

  // determine how many threads we need
  // each thread handling 256 elements
  unsigned int width, height; // thread space width and height
  unsigned int total_threads = 1;
  if (total_threads < MAX_TS_WIDTH) {
    width = total_threads;
    height = 1;
  }
  else {
    width = MAX_TS_WIDTH;
    height = total_threads / MAX_TS_WIDTH;
  }
  // Creates a CmThreadSpace object.
  // There are two usage models for the thread space. One is to define the
  // dependency between threads to run in the GPU. The other is to define a
  // thread space where each thread can get a pair of coordinates during
  // kernel execution. For this example, we use the latter usage model.
  CmThreadSpace *thread_space = nullptr;
  cm_result_check(device->CreateThreadSpace(width, height, thread_space));

  // Creates a task queue.
  // The CmQueue is an in-order queue. Tasks get executed according to the
  // order they are enqueued. The next task does not start execution until the
  // current task finishes.
  device->InitPrintBuffer();
  CmQueue *cmd_queue = nullptr;
  cm_result_check(device->CreateQueue(cmd_queue));

  // only call GPU prefix kernel when we have enough work to offload
  cm_result_check(bits_test_kernel->SetThreadCount(total_threads));


  // Creates a CmTask object.
  // The CmTask object is a container for CmKernel pointers. It is used to
  // enqueue the kernels for execution.
  CmTask *bits_test_task = nullptr;
  cm_result_check(device->CreateTask(bits_test_task));

  // Adds a CmKernel pointer to CmTask.
  // This task has one kernel, "cmk_radix_count".
  cm_result_check(bits_test_task->AddKernel(bits_test_kernel));
  //cm_result_check(prefix_task->AddKernel(prefix_kernel));


  std::cout << "Bits test Start..." << endl;

  clock_t start = clock(); // start timer


                           // Launches the task on the GPU. Enqueue is a non-blocking call, i.e. the
                           // function returns immediately without waiting for the GPU to start or
                           // finish execution of the task. The runtime will query the HW status. If
                           // the hardware is not busy, the runtime will submit the task to the
                           // driver/HW; otherwise, the runtime will submit the task to the driver/HW
                           // at another time.
                           // An event, "sync_event", is created to track the status of the task.
  CmEvent *event = nullptr;
  unsigned long time_out = -1;


  // For small input size, we only have a small number of threads
  // we don't call kernel to compute prefix sum. intead of, CPU simply performs the job
  cm_result_check(cmd_queue->Enqueue(bits_test_task, event, thread_space));
  cm_result_check(event->WaitForTaskFinished(time_out));

  clock_t end = clock(); // end timer
  std::cout << " GPU Prefix Time = " << end - start << " msec " << endl;
  std::cout << "== GPU output begins ==" << endl << endl;
  device->FlushPrintBuffer();
  std::cout << endl << "==  GPU output ends  ==" << endl;
  // Destroy a CmThreadSpace object.
  // CmThreadSpace will be destroyed when CmDevice is destroyed.
  // Here, the application destroys the CmThreadSpace object by itself.
  cm_result_check(device->DestroyThreadSpace(thread_space));
  // Destroys the CmDevice.
  // Also destroys surfaces, kernels, tasks, thread spaces, and queues that
  // were created using this device instance that have not explicitly been
  // destroyed by calling the respective destroy functions.
  cm_result_check(::DestroyCmDevice(device));
}

constexpr static uint64_t  all_set{ -1ULL };

void write_int(uint64_t* word, uint64_t x, uint8_t offset, const uint32_t len)
{
  x &= lo_set[len];
  if (offset + len < 64) {
    *word &=
      ((all_set << (offset + len)) | lo_set[offset]); // mask 1..10..01..1
    *word |= (x << offset);
    //		*word ^= ((*word ^ x) & (bits::lo_set[len] << offset) );
    //      surprisingly the above line is slower than the lines above
  }
  else {
    *word &=
      ((lo_set[offset]));  // mask 0....01..1
    *word |= (x << offset);
    if ((offset = (offset + len) & 0x3F)) { // offset+len > 64
      *(word + 1) &= (~lo_set[offset]); // mask 1...10..0
                                              //			*(word+1) &= bits::lo_unset[offset]; // mask 1...10..0
                                              //          surprisingly the above line is slower than the line above
      *(word + 1) |= (x >> (len - offset));
    }
  }
}

bool loadMatrix(uint32_t * k2treeMatrix, string filename) {
  ifstream file(filename);
  if (!file.good())
    return false;
  int value, i = 0;
  // Read an integer at a time from the line
  while (file >> value)
  {
    // Add the integers from a line to a 1D array (vector)
    k2treeMatrix[i++] = value;
  }
  file.close();
  return true;
}

bool loadFromFile(std::vector<uint32_t> &data, string filename) {
  ifstream file(filename);
  if (!file.good())
    return false;
  uint32_t value, i = 0;
  // Read an integer at a time from the line
  while (file >> value)
  {
    // Add the integers from a line to a 1D array (vector)
    data.push_back(value);
  }
  file.close();
  return true;
}

void K2treeConstructionTest(unsigned int size, string filename) {

  int iterations = 0, tempSize = size / K2_ENTRIES;

  while (tempSize >= K2_ENTRIES * 4) { // minimum matriz size to dispatch kernels
    iterations++;
    tempSize /= K2_ENTRIES;
  }
  std::cout << "Will dispatch Kernel " << iterations << " times for " << filename << "\n";

  uint32_t *k2treeMatrix;
  k2treeMatrix = (uint32_t*)CM_ALIGNED_MALLOC((size) * sizeof(uint32_t), 0x1000);
  if (!loadMatrix(k2treeMatrix, filename)) {
    std::cout << "File " << filename << " with matrix couldn't be read.\n";
    exit(1);
  }

  // Allocate space for final K2tree structures L and T
  uint64_t *L;
  L = (uint64_t*)CM_ALIGNED_MALLOC((size / 64) * sizeof(uint64_t), 0x1000);
  memset(L, 0, sizeof(uint64_t) * (size / 64));
  uint64_t *T;
  T = (uint64_t*)CM_ALIGNED_MALLOC((size / 64) * sizeof(uint64_t), 0x1000);
  memset(T, 0, sizeof(uint64_t) * (size / 64));
  // determine how many threads we need for each iteration
  unsigned int width, height; // thread space width and height
  unsigned int total_threads = size / K2_ENTRIES;
  width = total_threads / 2;
  height = total_threads / 2;

  // Every kernel i will write its results into Louts[i] and L
  uint32_t Lsize;
  Lsize = (K2_ENTRIES / WORD_SZ + 2) * total_threads; // (L + extabits) * total_threads
  uint32_t *Lout;
  Lout = (uint32_t *)CM_ALIGNED_MALLOC(Lsize * sizeof(uint32_t), 0x1000);
  uint32_t *Tsizes;
  Tsizes = (uint32_t *)CM_ALIGNED_MALLOC(iterations + 1 * sizeof(uint32_t), 0x1000);
  uint32_t **Touts;
  Touts = (uint32_t **)CM_ALIGNED_MALLOC(iterations + 1 * sizeof(uint32_t*), 0x1000);

  for (int i = 0, numThreads = total_threads; i <= iterations; i++, numThreads /= K2_ENTRIES) {
    Tsizes[i] = (ceil((K2_ENTRIES / pow(K2_VALUE, 2)) / WORD_SZ) + ceil((K2_ENTRIES / pow(K2_VALUE, 3)) / WORD_SZ) + 6) * numThreads; // 3 extra words for counting bits
    Touts[i] = (uint32_t *)CM_ALIGNED_MALLOC(Tsizes[i] * sizeof(uint32_t), 0x1000);
  }

  for (int i = 0; i <= iterations; i++)
    std::cout << "iteration " << i << ": " << size << " " << Lsize << " " << Tsizes[i] << " " << total_threads / pow(64, i) << endl;
  // Creates a CmDevice from scratch.
  // Param device: pointer to the CmDevice object.
  // Param version: CM API version supported by the runtime library.
  CmDevice *device = nullptr;
  unsigned int version = 0;
  cm_result_check(::CreateCmDevice(device, version));
  // The file linear_walker_genx.isa is generated when the kernels in the file
  // linear_walker_genx.cpp are compiled by the CM compiler.
  // Reads in the virtual ISA from "K2tree_genx.isa" to the code
  // buffer.
  std::string isa_code = cm::util::isa::loadFile("IndexBuilder_genx.isa");
  if (isa_code.size() == 0) {
    std::cout << "Error: empty ISA binary.\n";
    exit(1);
  }

  // Creates a CmProgram object consisting of the kernels loaded from the code
  // buffer.
  // Param isa_code.data(): Pointer to the code buffer containing the virtual
  // ISA.
  // Param isa_code.size(): Size in bytes of the code buffer containing the
  // virtual ISA.
  CmProgram *program = nullptr;
  cm_result_check(device->LoadProgram(const_cast<char*>(isa_code.data()),
    isa_code.size(),
    program));

  // Last_levels kernel will generate L and last 3 levels of T
  CmKernel *last_levels_kernel = nullptr;
  cm_result_check(device->CreateKernel(program,
    CM_KERNEL_FUNCTION(cmk_last_levels_construction),
    last_levels_kernel));
  CmKernel **mid_levels_kernel = nullptr;
  // Mid_levels kernel will generate 4 levels of T
  mid_levels_kernel = (CmKernel **)CM_ALIGNED_MALLOC(iterations * sizeof(CmKernel *), 0x1000);
  for (int i = 0; i < iterations; i++) {
    cm_result_check(device->CreateKernel(program,
      CM_KERNEL_FUNCTION(cmk_mid_levels_construction),
      mid_levels_kernel[i]));
  }


  std::cout << "# threads Kernel 1: " << total_threads << endl;

  // create buffers for input matrix, T and L
  CmBufferUP *matrixBuf;
  cm_result_check(device->CreateBufferUP(size * sizeof(unsigned int), (void*)k2treeMatrix, matrixBuf));
  //cm_result_check(inBuf->WriteSurface((const unsigned char*)k2treeMatrix, NULL));

  CmBuffer *LBuf;
  cm_result_check(device->CreateBuffer(Lsize * sizeof(unsigned int), LBuf));
  CmBuffer **TBuf;
  TBuf = (CmBuffer **)CM_ALIGNED_MALLOC(iterations + 1 * sizeof(CmBuffer *), 0x1000);

  for (int i = 0; i <= iterations; i++) {
    cm_result_check(device->CreateBuffer(Tsizes[i] * sizeof(unsigned int), TBuf[i]));
  }
  // When a surface is created by the CmDevice a SurfaceIndex object is
  // created. This object contains a unique index value that is mapped to the
  // surface.
  // Gets the input surface index.
  SurfaceIndex *input_idx = nullptr;
  cm_result_check(matrixBuf->GetIndex(input_idx));
  SurfaceIndex *L_idx = nullptr;
  cm_result_check(LBuf->GetIndex(L_idx));
  SurfaceIndex **T_idx = nullptr;
  T_idx = (SurfaceIndex **)CM_ALIGNED_MALLOC(iterations + 1 * sizeof(SurfaceIndex *), 0x1000);
  for (int i = 0; i <= iterations; i++) {
    cm_result_check(TBuf[i]->GetIndex(T_idx[i]));
  }
  //SurfaceIndex *output_idx = nullptr;
  //cm_result_check(outBuf->GetIndex(output_idx));

  // Creates a CmThreadSpace object.
  // There are two usage models for the thread space. One is to define the
  // dependency between threads to run in the GPU. The other is to define a
  // thread space where each thread can get a pair of coordinates during
  // kernel execution. For this example, we use the latter usage model.
  //CmThreadSpace *thread_space = nullptr;
  //cm_result_check(device->CreateThreadSpace(width, height, thread_space));

  // Creates a task queue.
  // The CmQueue is an in-order queue. Tasks get executed according to the
  // order they are enqueued. The next task does not start execution until the
  // current task finishes.
  device->InitPrintBuffer();
  CmQueue *cmd_queue = nullptr;
  cm_result_check(device->CreateQueue(cmd_queue));


  cm_result_check(last_levels_kernel->SetThreadCount(total_threads));
  cm_result_check(last_levels_kernel->SetKernelArg(0, sizeof(SurfaceIndex), input_idx));
  cm_result_check(last_levels_kernel->SetKernelArg(1, sizeof(SurfaceIndex), L_idx));
  cm_result_check(last_levels_kernel->SetKernelArg(2, sizeof(SurfaceIndex), T_idx[0]));
  int tt = sqrt(total_threads);
  cm_result_check(last_levels_kernel->SetKernelArg(3, sizeof(tt), &tt));
  int tid = 0;
  for (int x = 0; x < sqrt(total_threads); x++) { // set threads' (x,y)
    for (int y = 0; y < sqrt(total_threads); y++) {
      cm_result_check(last_levels_kernel->SetThreadArg(tid, 4, sizeof(x), &x));
      cm_result_check(last_levels_kernel->SetThreadArg(tid, 5, sizeof(y), &y));
      tid++;
    }
  }

  int numThreads = total_threads / K2_ENTRIES;
  for (int i = 1; i <= iterations; i++) { // only call GPU mid_levels kernel when we have enough work to offload
    cm_result_check(mid_levels_kernel[i - 1]->SetThreadCount(numThreads));
    cm_result_check(mid_levels_kernel[i - 1]->SetKernelArg(0, sizeof(SurfaceIndex), input_idx));
    cm_result_check(mid_levels_kernel[i - 1]->SetKernelArg(1, sizeof(SurfaceIndex), T_idx[i]));
    int nt = sqrt(numThreads);
    cm_result_check(mid_levels_kernel[i - 1]->SetKernelArg(2, sizeof(nt), &nt));

    tid = 0;
    for (int x = 0; x < sqrt(numThreads); x++) { // set threads' (x,y)
      for (int y = 0; y < sqrt(numThreads); y++) {
        cm_result_check(mid_levels_kernel[i - 1]->SetThreadArg(tid, 3, sizeof(x), &x));
        cm_result_check(mid_levels_kernel[i - 1]->SetThreadArg(tid, 4, sizeof(y), &y));
        tid++;
      }
    }
    numThreads /= K2_ENTRIES;
  }

  // Creates a CmTask object.
  // The CmTask object is a container for CmKernel pointers. It is used to
  // enqueue the kernels for execution.
  CmTask *last_levels_task = nullptr;
  cm_result_check(device->CreateTask(last_levels_task));
  CmTask **mid_levels_tasks = nullptr;
  mid_levels_tasks = (CmTask **)CM_ALIGNED_MALLOC(iterations * sizeof(CmTask *), 0x1000);
  for (int i = 0; i < iterations; i++)
    cm_result_check(device->CreateTask(mid_levels_tasks[i]));

  // Adds a CmKernel pointer to CmTask.
  cm_result_check(last_levels_task->AddKernel(last_levels_kernel));
  for (int i = 0; i < iterations; i++)
    cm_result_check(mid_levels_tasks[i]->AddKernel(mid_levels_kernel[i]));

  std::cout << "K2tree Construction test Start..." << endl;

  clock_t start = clock(); // start timer


                           // Launches the task on the GPU. Enqueue is a non-blocking call, i.e. the
                           // function returns immediately without waiting for the GPU to start or
                           // finish execution of the task. The runtime will query the HW status. If
                           // the hardware is not busy, the runtime will submit the task to the
                           // driver/HW; otherwise, the runtime will submit the task to the driver/HW
                           // at another time.
                           // An event, "sync_event", is created to track the status of the task.
  CmEvent *event = nullptr;
  unsigned long time_out = -1;

  // For small input size, we only have a small number of threads
  // we don't call kernel to compute prefix sum. intead of, CPU simply performs the job
  cm_result_check(cmd_queue->Enqueue(last_levels_task, event));
  cm_result_check(event->WaitForTaskFinished(time_out));

  cm_result_check(LBuf->ReadSurface((unsigned char *)Lout, event));
  /*
  cout << "L = ";
  for (int i = 0; i < Lsize; i++) {
    cout << Lout[i] << " ";
  }
  cout << endl;
  */
  int bit_idx = 0;
  uint8_t offset = 0;
  for (int i = 0; i < Lsize; i += 4) {
    if (Lout[i] > 0) {
      offset = bit_idx % 64;
      uint64_t x = Lout[i + 1];
      x |= ((uint64_t)Lout[i + 2]) << 32;
      write_int(&L[bit_idx / 64], x, offset, Lout[i]);
      bit_idx += Lout[i];
    }
  }

  cm_result_check(TBuf[0]->ReadSurface((unsigned char *)Touts[0], event));

  for (int i = 1; i <= iterations; i++) { // 256 elems is the minimum to dispatch 2nd kernel
    CmEvent *event2 = nullptr;
    cm_result_check(cmd_queue->Enqueue(mid_levels_tasks[i - 1], event2));
    cm_result_check(event2->WaitForTaskFinished(time_out));
    cm_result_check(TBuf[i]->ReadSurface((unsigned char *)Touts[i], event2));
  }

  // Build compact T
  write_int(&T[bit_idx / 64], (k2treeMatrix[0] | k2treeMatrix[1] << 1 | k2treeMatrix[2] << 2 | k2treeMatrix[3] << 3), 0, 4);
  bit_idx = 4;
  offset = 0;
  for (int i = iterations; i >= 0; i--) {
    for (int j = 0; j < Tsizes[i]; j += 4) {
      if (Touts[i][j] > 0) {
        offset = bit_idx % 64;
        uint64_t x = Touts[i][j + 1];
        write_int(&T[bit_idx / 64], x, offset, Touts[i][j]);
        bit_idx += Touts[i][j];
      }
    }
  }

  clock_t end = clock(); // end timer

  cout << "compact L = ";
  for (int i = 0; i < size / 64 && L[i] != 0; i++) {
    cout << L[i] << " ";
  }
  cout << endl;

  cout << "final compact T = ";
  for (int i = 0; i < size / 64 && T[i] != 0; i++) {
    cout << T[i] << " ";
  }
  cout << endl;

  std::cout << endl;
  std::cout << "== GPU output begins ==" << endl << endl;
  device->FlushPrintBuffer();
  std::cout << endl << "==  GPU output ends  ==" << endl;
  std::cout << " GPU Prefix Time = " << end - start << " msec " << endl;

  // Destroys the CmDevice.
  // Also destroys surfaces, kernels, tasks, thread spaces, and queues that
  // were created using this device instance that have not explicitly been
  // destroyed by calling the respective destroy functions.
  for (int i = 0; i < iterations; i++)
    cm_result_check(device->DestroyTask(mid_levels_tasks[i]));
  cm_result_check(::DestroyCmDevice(device));
  CM_ALIGNED_FREE(k2treeMatrix);
  CM_ALIGNED_FREE(Tsizes);
  for (int i = 0; i <= iterations; i++)
    CM_ALIGNED_FREE(Touts[i]);
  CM_ALIGNED_FREE(Touts);
  CM_ALIGNED_FREE(T);
  CM_ALIGNED_FREE(L);
  CM_ALIGNED_FREE(TBuf);
  CM_ALIGNED_FREE(T_idx);
  CM_ALIGNED_FREE(mid_levels_kernel);
  CM_ALIGNED_FREE(mid_levels_tasks);
}


void K2treeQueries(unsigned k, unsigned size, unsigned numThreads,
  string T_filename, string L_filename, string T_rank_filename, unsigned height, unsigned t_size, unsigned l_size) {

  std::vector<uint32_t> T, L, T_rank;
  if (!loadFromFile(T, T_filename)) {
    std::cout << "File " << T_filename << " couldn't be read.\n";
    exit(1);
  }
  if (!loadFromFile(L, L_filename)) {
    std::cout << "File " << L_filename << " couldn't be read.\n";
    exit(1);
  }
  if (!loadFromFile(T_rank, T_rank_filename)) {
    std::cout << "File " << T_rank_filename << " couldn't be read.\n";
    exit(1);
  }



  // Creates a CmDevice from scratch.
  // Param device: pointer to the CmDevice object.
  // Param version: CM API version supported by the runtime library.
  CmDevice *device = nullptr;
  unsigned int version = 0;
  cm_result_check(::CreateCmDevice(device, version));
  // The file linear_walker_genx.isa is generated when the kernels in the file
  // linear_walker_genx.cpp are compiled by the CM compiler.
  // Reads in the virtual ISA from "K2tree_genx.isa" to the code
  // buffer.
  std::string isa_code = cm::util::isa::loadFile("IndexBuilder_genx.isa");
  if (isa_code.size() == 0) {
    std::cout << "Error: empty ISA binary.\n";
    exit(1);
  }

  // Creates a CmProgram object consisting of the kernels loaded from the code
  // buffer.
  // Param isa_code.data(): Pointer to the code buffer containing the virtual
  // ISA.
  // Param isa_code.size(): Size in bytes of the code buffer containing the
  // virtual ISA.
  CmProgram *program = nullptr;
  cm_result_check(device->LoadProgram(const_cast<char*>(isa_code.data()),
    isa_code.size(),
    program));

  CmKernel *neighbors_kernel = nullptr;
  cm_result_check(device->CreateKernel(program,
    CM_KERNEL_FUNCTION(cmk_neighbors_test),
    neighbors_kernel));
  CmKernel *range_kernel = nullptr;
  cm_result_check(device->CreateKernel(program,
    CM_KERNEL_FUNCTION(cmk_range_test),
    range_kernel));

  // create buffers for input matrix, T and L
  CmBuffer *TBuf;
  cm_result_check(device->CreateBuffer(T.size() * sizeof(unsigned int), TBuf));
  cm_result_check(TBuf->WriteSurface((const unsigned char*)T.data(), NULL));
  CmBuffer *LBuf;
  cm_result_check(device->CreateBuffer(L.size() * sizeof(unsigned int), LBuf));
  cm_result_check(LBuf->WriteSurface((const unsigned char*)L.data(), NULL));
  CmBuffer *T_rankBuf;
  cm_result_check(device->CreateBuffer(T_rank.size() * sizeof(unsigned int), T_rankBuf));
  cm_result_check(T_rankBuf->WriteSurface((const unsigned char*)T_rank.data(), NULL));

  // When a surface is created by the CmDevice a SurfaceIndex object is
  // created. This object contains a unique index value that is mapped to the
  // surface.
  // Gets the input surface index.
  SurfaceIndex *T_idx = nullptr;
  cm_result_check(TBuf->GetIndex(T_idx));
  SurfaceIndex *L_idx = nullptr;
  cm_result_check(LBuf->GetIndex(L_idx));
  SurfaceIndex *T_rank_idx = nullptr;
  cm_result_check(T_rankBuf->GetIndex(T_rank_idx));

  //SurfaceIndex *output_idx = nullptr;
  //cm_result_check(outBuf->GetIndex(output_idx));

  // Creates a CmThreadSpace object.
  // There are two usage models for the thread space. One is to define the
  // dependency between threads to run in the GPU. The other is to define a
  // thread space where each thread can get a pair of coordinates during
  // kernel execution. For this example, we use the latter usage model.
  //CmThreadSpace *thread_space = nullptr;
  //cm_result_check(device->CreateThreadSpace(width, height, thread_space));

  // Creates a task queue.
  // The CmQueue is an in-order queue. Tasks get executed according to the
  // order they are enqueued. The next task does not start execution until the
  // current task finishes.
  device->InitPrintBuffer();
  CmQueue *cmd_queue = nullptr;
  cm_result_check(device->CreateQueue(cmd_queue));

  // for range queries and their thread space
  unsigned width = sqrt(numThreads);
  unsigned height_ = sqrt(numThreads);
  unsigned block = size / width;
  CmThreadSpace *thread_space = nullptr;
  cm_result_check(device->CreateThreadSpace(width, height_, thread_space));

  cm_result_check(neighbors_kernel->SetThreadCount(numThreads));
  //cm_result_check(range_kernel->SetThreadCount(numThreads));
  cm_result_check(neighbors_kernel->SetKernelArg(0, sizeof(SurfaceIndex), T_idx));
  cm_result_check(range_kernel->SetKernelArg(0, sizeof(SurfaceIndex), T_idx));
  cm_result_check(neighbors_kernel->SetKernelArg(1, sizeof(SurfaceIndex), L_idx));
  cm_result_check(range_kernel->SetKernelArg(1, sizeof(SurfaceIndex), L_idx));
  cm_result_check(neighbors_kernel->SetKernelArg(2, sizeof(SurfaceIndex), T_rank_idx));
  cm_result_check(range_kernel->SetKernelArg(2, sizeof(SurfaceIndex), T_rank_idx));
  cm_result_check(neighbors_kernel->SetKernelArg(3, sizeof(uint32_t), &t_size));
  cm_result_check(range_kernel->SetKernelArg(3, sizeof(uint32_t), &t_size));
  cm_result_check(neighbors_kernel->SetKernelArg(4, sizeof(uint32_t), &l_size));
  cm_result_check(range_kernel->SetKernelArg(4, sizeof(uint32_t), &l_size));
  cm_result_check(neighbors_kernel->SetKernelArg(5, sizeof(uint32_t), &height));
  cm_result_check(range_kernel->SetKernelArg(5, sizeof(uint32_t), &height));
  cm_result_check(neighbors_kernel->SetKernelArg(6, sizeof(uint32_t), &k));
  cm_result_check(range_kernel->SetKernelArg(6, sizeof(uint32_t), &k));


  unsigned chunk = (size) / numThreads;
  for (unsigned i = 0; i < numThreads; i++) {
    unsigned start = chunk * i;
    unsigned end = chunk * i + chunk;
    cm_result_check(neighbors_kernel->SetThreadArg(i, 7, sizeof(start), &start));

    cm_result_check(neighbors_kernel->SetThreadArg(i, 8, sizeof(end), &end));

  }
  cm_result_check(range_kernel->SetKernelArg(7, sizeof(block), &block));
  cm_result_check(range_kernel->SetKernelArg(8, sizeof(block), &block));
  // Creates a CmTask object.
  // The CmTask object is a container for CmKernel pointers. It is used to
  // enqueue the kernels for execution.
  CmTask *neighbors_task = nullptr;
  cm_result_check(device->CreateTask(neighbors_task));
  CmTask *range_task = nullptr;
  cm_result_check(device->CreateTask(range_task));
  // Adds a CmKernel pointer to CmTask.
  cm_result_check(neighbors_task->AddKernel(neighbors_kernel));
  cm_result_check(range_task->AddKernel(range_kernel));


  std::cout << "K2tree neighbors test Start..." << endl;

  clock_t start = clock(); // start timer


                           // Launches the task on the GPU. Enqueue is a non-blocking call, i.e. the
                           // function returns immediately without waiting for the GPU to start or
                           // finish execution of the task. The runtime will query the HW status. If
                           // the hardware is not busy, the runtime will submit the task to the
                           // driver/HW; otherwise, the runtime will submit the task to the driver/HW
                           // at another time.
                           // An event, "sync_event", is created to track the status of the task.
  CmEvent *event = nullptr;
  unsigned long time_out = -1;

  // For small input size, we only have a small number of threads
  // we don't call kernel to compute prefix sum. intead of, CPU simply performs the job
  cm_result_check(cmd_queue->Enqueue(neighbors_task, event));
  cm_result_check(event->WaitForTaskFinished(time_out));

  clock_t end = clock(); // end timer

  std::cout << endl;
  std::cout << "== GPU output begins ==" << endl << endl;
  device->FlushPrintBuffer();
  std::cout << endl << "==  GPU output ends  ==" << endl;
  std::cout << " GPU Prefix Time = " << end - start << " msec " << endl;


  /****************************************************
  * Kernel for Range query
  ****************************************************/
  device->InitPrintBuffer();

  std::cout << "K2tree range test Start..." << endl;

  start = clock(); // start timer


                           // Launches the task on the GPU. Enqueue is a non-blocking call, i.e. the
                           // function returns immediately without waiting for the GPU to start or
                           // finish execution of the task. The runtime will query the HW status. If
                           // the hardware is not busy, the runtime will submit the task to the
                           // driver/HW; otherwise, the runtime will submit the task to the driver/HW
                           // at another time.
                           // An event, "sync_event", is created to track the status of the task.

  // For small input size, we only have a small number of threads
  // we don't call kernel to compute prefix sum. intead of, CPU simply performs the job
  cm_result_check(cmd_queue->Enqueue(range_task, event, thread_space));
  cm_result_check(event->WaitForTaskFinished(time_out));

  end = clock(); // end timer

  std::cout << endl;
  std::cout << "== GPU output begins ==" << endl << endl;
  device->FlushPrintBuffer();
  std::cout << endl << "==  GPU output ends  ==" << endl;
  std::cout << " GPU Range Time = " << end - start << " msec " << endl;

  // Destroys the CmDevice.
  // Also destroys surfaces, kernels, tasks, thread spaces, and queues that
  // were created using this device instance that have not explicitly been
  // destroyed by calling the respective destroy functions.
  cm_result_check(device->DestroyTask(neighbors_task));
  cm_result_check(device->DestroyTask(range_task));
  cm_result_check(::DestroyCmDevice(device));
}



void K2treeConstructionFromEdges(unsigned int size, string filename) {


  uint32_t *edges;
  edges = (uint32_t*)CM_ALIGNED_MALLOC((size) * sizeof(uint32_t), 0x1000);

  //set values
  edges[0] = 6; // 1;
  edges[1] = 7; // 18;
  edges[2] = 10; // 19;
  edges[3] = 11; // 20;
  edges[4] = 18; // 22;
  edges[5] = 30; // 23;
  edges[6] = 55; // 25;
  edges[7] = 62; // 41;
  edges[8] = 73; // 42;
  edges[9] = 98; // 48;
  edges[10] = 104; // 52;
  edges[11] = 146; // 53;
  edges[12] = 148; // 54;
  edges[13] = 150; // 0;
  edges[14] = 0;
  edges[15] = 0;
  edges[16] = 0;
  edges[17] = 0;
  edges[18] = 0;
  edges[19] = 0;
  edges[20] = 0;
  edges[21] = 0;
  edges[22] = 0;
  edges[23] = 0;
  edges[24] = 0;
  edges[25] = 0;
  edges[26] = 0;
  edges[27] = 0;
  edges[28] = 0;
  edges[29] = 0;
  edges[30] = 0;
  edges[31] = 0;

  // Allocate space for final K2tree structures L and T
  uint64_t *L;
  L = (uint64_t*)CM_ALIGNED_MALLOC((size / 64) * sizeof(uint64_t), 0x1000);
  memset(L, 0, sizeof(uint64_t) * (size / 64));
  uint64_t *T;
  T = (uint64_t*)CM_ALIGNED_MALLOC((size / 64) * sizeof(uint64_t), 0x1000);
  memset(T, 0, sizeof(uint64_t) * (size / 64));
  // determine how many threads we need for each iteration
  unsigned int width, height; // thread space width and height
  unsigned int total_threads = 1;
  //width = total_threads / 2;
  //height = total_threads / 2;


  // Creates a CmDevice from scratch.
  // Param device: pointer to the CmDevice object.
  // Param version: CM API version supported by the runtime library.
  CmDevice *device = nullptr;
  unsigned int version = 0;
  cm_result_check(::CreateCmDevice(device, version));
  // The file linear_walker_genx.isa is generated when the kernels in the file
  // linear_walker_genx.cpp are compiled by the CM compiler.
  // Reads in the virtual ISA from "K2tree_genx.isa" to the code
  // buffer.
  std::string isa_code = cm::util::isa::loadFile("IndexBuilder_genx.isa");
  if (isa_code.size() == 0) {
    std::cout << "Error: empty ISA binary.\n";
    exit(1);
  }

  // Creates a CmProgram object consisting of the kernels loaded from the code
  // buffer.
  // Param isa_code.data(): Pointer to the code buffer containing the virtual
  // ISA.
  // Param isa_code.size(): Size in bytes of the code buffer containing the
  // virtual ISA.
  CmProgram *program = nullptr;
  cm_result_check(device->LoadProgram(const_cast<char*>(isa_code.data()),
    isa_code.size(),
    program));

  // Last_levels kernel will generate L and last 3 levels of T
  CmKernel *construction_edges_kernel = nullptr;
  cm_result_check(device->CreateKernel(program,
    CM_KERNEL_FUNCTION(cmk_construction_from_edges),
    construction_edges_kernel));

  std::cout << "# threads Kernel: " << total_threads << endl;

  // create buffers for input matrix, T and L
  CmBuffer *edgesBuf;
  cm_result_check(device->CreateBuffer(size * sizeof(unsigned int), edgesBuf));
  cm_result_check(edgesBuf->WriteSurface((const unsigned char*)edges, NULL));


  // When a surface is created by the CmDevice a SurfaceIndex object is
  // created. This object contains a unique index value that is mapped to the
  // surface.
  // Gets the input surface index.
  SurfaceIndex *edges_idx = nullptr;
  cm_result_check(edgesBuf->GetIndex(edges_idx));
  ;

  // Creates a CmThreadSpace object.
  // There are two usage models for the thread space. One is to define the
  // dependency between threads to run in the GPU. The other is to define a
  // thread space where each thread can get a pair of coordinates during
  // kernel execution. For this example, we use the latter usage model.
  //CmThreadSpace *thread_space = nullptr;
  //cm_result_check(device->CreateThreadSpace(width, height, thread_space));

  // Creates a task queue.
  // The CmQueue is an in-order queue. Tasks get executed according to the
  // order they are enqueued. The next task does not start execution until the
  // current task finishes.
  device->InitPrintBuffer();
  CmQueue *cmd_queue = nullptr;
  cm_result_check(device->CreateQueue(cmd_queue));


  cm_result_check(construction_edges_kernel->SetThreadCount(total_threads));
  cm_result_check(construction_edges_kernel->SetKernelArg(0, sizeof(SurfaceIndex), edges_idx));
  unsigned int temp = 0;

  unsigned chunk = 13 / 2;
  for (unsigned i = 0; i < total_threads; i++) {
    unsigned start = chunk * i;
    unsigned end = chunk * i + chunk;
    cm_result_check(construction_edges_kernel->SetThreadArg(i, 1, sizeof(start), &start));

    cm_result_check(construction_edges_kernel->SetThreadArg(i, 2, sizeof(start), &start));

    cm_result_check(construction_edges_kernel->SetThreadArg(i, 3, sizeof(end), &end));

  }



  // Creates a CmTask object.
  // The CmTask object is a container for CmKernel pointers. It is used to
  // enqueue the kernels for execution.
  CmTask *construction_edges_task = nullptr;
  cm_result_check(device->CreateTask(construction_edges_task));

  // Adds a CmKernel pointer to CmTask.
  cm_result_check(construction_edges_task->AddKernel(construction_edges_kernel));

  std::cout << "K2tree Construction test Start..." << endl;

  clock_t start = clock(); // start timer


                           // Launches the task on the GPU. Enqueue is a non-blocking call, i.e. the
                           // function returns immediately without waiting for the GPU to start or
                           // finish execution of the task. The runtime will query the HW status. If
                           // the hardware is not busy, the runtime will submit the task to the
                           // driver/HW; otherwise, the runtime will submit the task to the driver/HW
                           // at another time.
                           // An event, "sync_event", is created to track the status of the task.
  CmEvent *event = nullptr;
  unsigned long time_out = -1;

  // For small input size, we only have a small number of threads
  // we don't call kernel to compute prefix sum. intead of, CPU simply performs the job
  cm_result_check(cmd_queue->Enqueue(construction_edges_task, event));
  cm_result_check(event->WaitForTaskFinished(time_out));

  clock_t end = clock(); // end timer


  std::cout << endl;
  std::cout << "== GPU output begins ==" << endl << endl;
  device->FlushPrintBuffer();
  std::cout << endl << "==  GPU output ends  ==" << endl;
  std::cout << " GPU Prefix Time = " << end - start << " msec " << endl;

  // Destroys the CmDevice.
  // Also destroys surfaces, kernels, tasks, thread spaces, and queues that
  // were created using this device instance that have not explicitly been
  // destroyed by calling the respective destroy functions.

  CM_ALIGNED_FREE(edges);
  CM_ALIGNED_FREE(T);
  CM_ALIGNED_FREE(L);
}

void generateMortonNumbers() {

  int numEdges = 64;
  int numMortonNumbers = numEdges / 2;

  uint32_t *edges;
  edges = (uint32_t*)CM_ALIGNED_MALLOC((numEdges) * sizeof(uint32_t), 0x1000);
  memset(edges, 0, sizeof(uint32_t) * numEdges);
    //set values
  edges[0] = 152;
  edges[1] = 43;
  edges[2] = 0xffffffff;

  // Allocate space for output
  uint64_t *mortonNumbers;
  mortonNumbers = (uint64_t*)CM_ALIGNED_MALLOC((numMortonNumbers) * sizeof(uint64_t), 0x1000);
  memset(mortonNumbers, 0, sizeof(uint64_t) * (numMortonNumbers));

  // determine how many threads we need for each iteration
  unsigned int width, height; // thread space width and height
  unsigned int total_threads = 1;
  //width = total_threads / 2;
  //height = total_threads / 2;


  // Creates a CmDevice from scratch.
  // Param device: pointer to the CmDevice object.
  // Param version: CM API version supported by the runtime library.
  CmDevice *device = nullptr;
  unsigned int version = 0;
  cm_result_check(::CreateCmDevice(device, version));
  // The file linear_walker_genx.isa is generated when the kernels in the file
  // linear_walker_genx.cpp are compiled by the CM compiler.
  // Reads in the virtual ISA from "K2tree_genx.isa" to the code
  // buffer.
  std::string isa_code = cm::util::isa::loadFile("IndexBuilder_genx.isa");
  if (isa_code.size() == 0) {
    std::cout << "Error: empty ISA binary.\n";
    exit(1);
  }

  // Creates a CmProgram object consisting of the kernels loaded from the code
  // buffer.
  // Param isa_code.data(): Pointer to the code buffer containing the virtual
  // ISA.
  // Param isa_code.size(): Size in bytes of the code buffer containing the
  // virtual ISA.
  CmProgram *program = nullptr;
  cm_result_check(device->LoadProgram(const_cast<char*>(isa_code.data()),
    isa_code.size(),
    program));

  // Last_levels kernel will generate L and last 3 levels of T
  CmKernel *morton_kernel = nullptr;
  cm_result_check(device->CreateKernel(program,
    CM_KERNEL_FUNCTION(cmk_generate_morton_numbers),
    morton_kernel));

  std::cout << "# threads Kernel: " << total_threads << endl;

  // create buffers for input/output
  CmBuffer *edgesBuf;
  cm_result_check(device->CreateBuffer(numEdges * sizeof(unsigned int), edgesBuf));
  cm_result_check(edgesBuf->WriteSurface((const unsigned char*)edges, NULL));
  CmBuffer *mortonBuf;
  cm_result_check(device->CreateBuffer(numMortonNumbers * sizeof(unsigned int), mortonBuf));



  // When a surface is created by the CmDevice a SurfaceIndex object is
  // created. This object contains a unique index value that is mapped to the
  // surface.
  // Gets the input surface index.
  SurfaceIndex *edges_idx = nullptr;
  cm_result_check(edgesBuf->GetIndex(edges_idx));
  SurfaceIndex *morton_idx = nullptr;
  cm_result_check(mortonBuf->GetIndex(morton_idx));
  ;

  // Creates a CmThreadSpace object.
  // There are two usage models for the thread space. One is to define the
  // dependency between threads to run in the GPU. The other is to define a
  // thread space where each thread can get a pair of coordinates during
  // kernel execution. For this example, we use the latter usage model.
  //CmThreadSpace *thread_space = nullptr;
  //cm_result_check(device->CreateThreadSpace(width, height, thread_space));

  // Creates a task queue.
  // The CmQueue is an in-order queue. Tasks get executed according to the
  // order they are enqueued. The next task does not start execution until the
  // current task finishes.
  device->InitPrintBuffer();
  CmQueue *cmd_queue = nullptr;
  cm_result_check(device->CreateQueue(cmd_queue));


  cm_result_check(morton_kernel->SetThreadCount(total_threads));
  cm_result_check(morton_kernel->SetKernelArg(0, sizeof(SurfaceIndex), edges_idx));
  cm_result_check(morton_kernel->SetKernelArg(1, sizeof(SurfaceIndex), morton_idx));




  // Creates a CmTask object.
  // The CmTask object is a container for CmKernel pointers. It is used to
  // enqueue the kernels for execution.
  CmTask *construction_edges_task = nullptr;
  cm_result_check(device->CreateTask(construction_edges_task));

  // Adds a CmKernel pointer to CmTask.
  cm_result_check(construction_edges_task->AddKernel(morton_kernel));

  std::cout << "K2tree Construction test Start..." << endl;

  clock_t start = clock(); // start timer


                           // Launches the task on the GPU. Enqueue is a non-blocking call, i.e. the
                           // function returns immediately without waiting for the GPU to start or
                           // finish execution of the task. The runtime will query the HW status. If
                           // the hardware is not busy, the runtime will submit the task to the
                           // driver/HW; otherwise, the runtime will submit the task to the driver/HW
                           // at another time.
                           // An event, "sync_event", is created to track the status of the task.
  CmEvent *event = nullptr;
  unsigned long time_out = -1;

  // For small input size, we only have a small number of threads
  // we don't call kernel to compute prefix sum. intead of, CPU simply performs the job
  cm_result_check(cmd_queue->Enqueue(construction_edges_task, event));
  cm_result_check(event->WaitForTaskFinished(time_out));

  clock_t end = clock(); // end timer

  cm_result_check(mortonBuf->ReadSurface((unsigned char *)mortonNumbers, event));

  std::cout << endl;
  std::cout << "== GPU output begins ==" << endl << endl;
  device->FlushPrintBuffer();
  std::cout << endl << "==  GPU output ends  ==" << endl;
  std::cout << " GPU Prefix Time = " << end - start << " msec " << endl;

  std::cout << "Morton number " << mortonNumbers[0] << std::endl;
  std::cout << "Morton number " << mortonNumbers[1] << std::endl;
  std::cout << "Morton number " << mortonNumbers[2] << std::endl;
  std::cout << "Morton number " << mortonNumbers[3] << std::endl;

  // Destroys the CmDevice.
  // Also destroys surfaces, kernels, tasks, thread spaces, and queues that
  // were created using this device instance that have not explicitly been
  // destroyed by calling the respective destroy functions.

  CM_ALIGNED_FREE(edges);
  CM_ALIGNED_FREE(mortonNumbers);

}

void cmk_radix_count(SurfaceIndex input, SurfaceIndex output, unsigned int n);
void cmk_radix_bucket(SurfaceIndex input, SurfaceIndex table,
  SurfaceIndex output, unsigned int bin0_cnt, unsigned int bin1_cnt,
  unsigned int bin2_cnt, unsigned int bin3_cnt, unsigned int n);

#define LOG2_ELEMENTS 8
//
// validate radix_count result
//
bool validate_count(uint64_t inputs[], unsigned int result[],
  unsigned int total_threads, unsigned int size,
  unsigned n) {
  unsigned int binCount[4];
  binCount[0] = binCount[1] = binCount[2] = binCount[3] = 0;
  unsigned long long mask = 0x3 << n;
  for (int i = 0; i < size; i++) {
    binCount[(inputs[i] & mask) >> n]++;
  }

  unsigned int total_cnt[BIN_NUM];
  total_cnt[0] = total_cnt[1] = total_cnt[2] = total_cnt[3] = 0;
  for (int i = 0; i < total_threads; i++) {
    total_cnt[0] += result[i*BIN_NUM];
    total_cnt[1] += result[i*BIN_NUM + 1];
    total_cnt[2] += result[i*BIN_NUM + 2];
    total_cnt[3] += result[i*BIN_NUM + 3];
  }

  cout << "Expected result  for n=" << n << ": " <<
    binCount[0] << " " <<
    binCount[1] << " " <<
    binCount[2] << " " <<
    binCount[3] << " " << endl;
  cout << "result " <<
    total_cnt[0] << " " <<
    total_cnt[1] << " " <<
    total_cnt[2] << " " <<
    total_cnt[3] << " " << endl;
  return (binCount[0] == total_cnt[0] &&
    binCount[1] == total_cnt[1] &&
    binCount[2] == total_cnt[2] &&
    binCount[3] == total_cnt[3]);
}
//
// validate bin's contents
//
bool validate_bin(uint64_t outputs[], unsigned int binCount[], unsigned int n) {
  unsigned long long mask = 0x3 << n;
  int idx = 0;
  for (int i = 0; i < binCount[0]; i++, idx++) {
    if (((outputs[idx] & mask) >> n) != 0) {
      cout << "Bin0 error at idx = " << idx << " value= " << outputs[idx] << endl;
      return false;
    }
  }
  for (int i = 0; i < binCount[1]; i++, idx++) {
    if (((outputs[idx] & mask) >> n) != 1) {
      cout << "Bin1 error at idx = " << idx << " value= " << outputs[idx] << endl;
      return false;
    }
  }
  for (int i = 0; i < binCount[2]; i++, idx++) {
    if (((outputs[idx] & mask) >> n) != 2) {
      cout << "Bin2 error at idx = " << idx << " value= " << outputs[idx] << endl;
      return false;
    }
  }
  for (int i = 0; i < binCount[3]; i++, idx++) {
    if (((outputs[idx] & mask) >> n) != 3) {
      cout << "Bin3 error at idx = " << idx << " value= " << outputs[idx] << endl;
      return false;
    }
  }
  return true;
}

static unsigned int clock_prefix = 0;
void  compute_prefixsum(unsigned int prefixSum[], unsigned int total_threads) {
#if _DEBUG
  cout << "Count Table" << endl;
  for (int i = 0; i < total_threads; i++)
    cout << "\t" << prefixSum[i*BIN_NUM] << "\t" << prefixSum[i*BIN_NUM + 1]
    << "\t" << prefixSum[i*BIN_NUM + 2] << "\t" << prefixSum[i*BIN_NUM + 3] << endl;

  cout << "Prefix Sum Table " << endl;
  cout << "\t" << prefixSum[0] << "\t" << prefixSum[1] << "\t" << prefixSum[2] << "\t" << prefixSum[3] << endl;
#endif
  clock_t start = clock();
  for (int i = 1; i < total_threads; i++) {
    prefixSum[i*BIN_NUM] += prefixSum[(i - 1)*BIN_NUM];
    prefixSum[i*BIN_NUM + 1] += prefixSum[(i - 1)*BIN_NUM + 1];
    prefixSum[i*BIN_NUM + 2] += prefixSum[(i - 1)*BIN_NUM + 2];
    prefixSum[i*BIN_NUM + 3] += prefixSum[(i - 1)*BIN_NUM + 3];
#if _DEBUG
    cout << "\t" << prefixSum[i*BIN_NUM] << "\t" << prefixSum[i*BIN_NUM + 1]
      << "\t" << prefixSum[i*BIN_NUM + 2] << "\t" << prefixSum[i*BIN_NUM + 3] << endl;
#endif
  }
  clock_t end = clock();

  clock_prefix += end - start;
}

void validate_sorted_result(uint64_t expectOutputs[], uint64_t result[], unsigned int size) {
  clock_t start = clock(); // start timer
  std::sort(expectOutputs, expectOutputs + size);
  clock_t end = clock(); // end timer
  cout << " CPU Sorting Time = " << end - start << " msec " << endl;

  bool pass = true;
  for (unsigned int i = 0; i < size; ++i) {
    if (expectOutputs[i] != result[i]) {
      cout << "Difference is detected at i= " << i << " Expect = " << expectOutputs[i] << " Actual = " << result[i] << endl;
      pass = false;
      break;
    }
  }
  cout << "Radix Sort " << (pass ? "PASSED" : "FAILED") << endl;
}

void dumpElems(uint64_t elems[], unsigned int size){
  cout << "Elements: ";
  for(int i = 0; i < size; i++){
    cout << elems[i] << ", ";
  }
  cout << std::endl;
}

int radixSort(){
  uint64_t * pInputs;
  uint64_t * pActualOutputs;
  uint64_t * pExpectOutputs;
  unsigned int * prefixSum;

  unsigned int size = 1 << LOG2_ELEMENTS;
  // prepare intput data
  pInputs = (uint64_t*)CM_ALIGNED_MALLOC(size * sizeof(uint64_t), 0x1000);
  for (unsigned int i = 0; i < size; ++i) {
    pInputs[i] = (rand() << 32) + rand();
    // pInputs_[i] = rand() % (1 << 15);
  }
  // prepare output buffer for sorted result
  pActualOutputs = (uint64_t*)CM_ALIGNED_MALLOC(size * sizeof(uint64_t), 0x1000);
  memset(pActualOutputs, 0, sizeof(uint64_t) * size);
  // prepare validation result. call std::sort to get the expected result
  pExpectOutputs = new uint64_t[size];
  memcpy(pExpectOutputs, pInputs, sizeof(uint64_t) * size);
  std::sort(pExpectOutputs, pExpectOutputs + size);
  //dumpElems(pInputs, size);
  //dumpElems(pExpectOutputs, size);

  // Creates a CmDevice
  // Param device: pointer to the CmDevice object.
  // Param version: CM API version supported by the runtime library.
  CmDevice *device = nullptr;
  unsigned int version = 0;
  cm_result_check(::CreateCmDevice(device, version));
  // The file radix_genx.isa is generated by the CM compiler.
  // Reads in the virtual ISA from "radix_genx.isa" to the code
  // buffer.
  std::string isa_code = cm::util::isa::loadFile("IndexBuilder_genx.isa");
  if (isa_code.size() == 0) {
    std::cerr << "Error: empty ISA binary.\n";
    exit(1);
  }
  // Creates a CmProgram object consisting of the kernels loaded
  // from the code buffer.
  CmProgram *program = nullptr;
  cm_result_check(device->LoadProgram(const_cast<char*>(isa_code.data()),
    isa_code.size(),
    program));

  // Creates the radix bin-count kernel.
  CmKernel *count_kernel = nullptr;
  cm_result_check(device->CreateKernel(program,
    CM_KERNEL_FUNCTION(cmk_radix_count),
    count_kernel));
  // create radix bucket kernel
  CmKernel *bucket_kernel = nullptr;
  cm_result_check(device->CreateKernel(program,
    CM_KERNEL_FUNCTION(cmk_radix_bucket),
    bucket_kernel));

  // determine how many threads we need
  // each thread handling 256 elements
  unsigned int width, height; // thread space width and height
  unsigned int total_threads = size / BASE_SZ;
  if (total_threads < MAX_TS_WIDTH) {
    width = total_threads;
    height = 1;
  }
  else {
    width = MAX_TS_WIDTH;
    height = total_threads / MAX_TS_WIDTH;
  }
  // create buffers for input and output and prefix sum table
  // in system-memory, zero-copy for GPU-CPU sharing.
  CmBufferUP *inBuf;
  cm_result_check(device->CreateBufferUP(size * sizeof(uint64_t), (void *)pInputs, inBuf));
  CmBufferUP *outBuf;
  cm_result_check(device->CreateBufferUP(size * sizeof(uint64_t), (void *)pActualOutputs, outBuf));
  // prepare prefixSum table
  prefixSum = (unsigned int*)CM_ALIGNED_MALLOC(total_threads*BIN_NUM * sizeof(unsigned int), 0x1000);
  CmBufferUP *prefixBuf;
  cm_result_check(device->CreateBufferUP(total_threads*BIN_NUM * sizeof(unsigned int), (void *)prefixSum, prefixBuf));
  // When a surface is created by the CmDevice a SurfaceIndex object is
  // created. This object contains a unique index value that is mapped to the
  // surface.
  // Gets the input surface index.
  SurfaceIndex *input_idx = nullptr;
  cm_result_check(inBuf->GetIndex(input_idx));
  SurfaceIndex *output_idx = nullptr;
  cm_result_check(outBuf->GetIndex(output_idx));
  SurfaceIndex *prefix_idx = nullptr;
  cm_result_check(prefixBuf->GetIndex(prefix_idx));

  // Creates a CmThreadSpace object.
  CmThreadSpace *thread_space = nullptr;
  cm_result_check(device->CreateThreadSpace(width, height, thread_space));

  // Creates a task queue.
  CmQueue *cmd_queue = nullptr;
  cm_result_check(device->CreateQueue(cmd_queue));

  // Creates CmTask objects.
  // The CmTask object is a container for CmKernel pointers. It is used to
  // enqueue the kernels for execution.
  CmTask *cnt_task = nullptr;
  cm_result_check(device->CreateTask(cnt_task));
  CmTask *bucket_task = nullptr;
  cm_result_check(device->CreateTask(bucket_task));
  // Adds a CmKernel pointer to CmTask.
  // This task has one kernel, "cmk_radix_count".
  cm_result_check(cnt_task->AddKernel(count_kernel));
  cm_result_check(bucket_task->AddKernel(bucket_kernel));
  // Inits the print buffer.
  // Here the buffer used by printf is allocated.
  cm_result_check(device->InitPrintBuffer());

  cout << "Radix Sort (" << size << ") Start..." << endl;

  clock_t start = clock(); // start timer

                           // 16 iterations for sorting 32-bit unsigned numbers, 2-bit each iteration
  for (int n = 0; n <= 64; n += N_BITS) {
    // cmk_radix_count(SurfaceIndex input, SurfaceIndex prefix, unsigned int n).
    // set argument for radix_count
    // determine even or odd iteration. alternate in and out buffers
    bool even_iteration = ((n >> 1) & 0x1) == 0;
    if (even_iteration) {
      cm_result_check(count_kernel->SetKernelArg(0, sizeof(SurfaceIndex), input_idx));
    }
    else {
      cm_result_check(count_kernel->SetKernelArg(0, sizeof(SurfaceIndex), output_idx));
    }
    cm_result_check(count_kernel->SetKernelArg(1, sizeof(SurfaceIndex), prefix_idx));
    cm_result_check(count_kernel->SetKernelArg(2, sizeof(int), &n));
    // Launches the task on the GPU. Enqueue is a non-blocking call, i.e. the
    // function returns immediately without waiting for the GPU to start or
    // finish execution of the task. The runtime will query the HW status. If
    // the hardware is not busy, the runtime will submit the task to the
    // driver/HW; otherwise, the runtime will submit the task to the driver/HW
    // at another time.
    // An event, "sync_event", is created to track the status of the task.
    CmEvent *event = nullptr;
    cm_result_check(cmd_queue->Enqueue(cnt_task, event, thread_space));

    // Waits for the task associated with "sync_event" finishing execution
    // on the GPU.
    unsigned long time_out = -1;
    cm_result_check(event->WaitForTaskFinished(time_out));

    bool pass = true;
#ifdef _DEBUG
    // validate bin count result
    pass = validate_count(even_iteration ? pInputs : pActualOutputs, prefixSum, total_threads, size, n);
#endif

    // compute prefix sum on CPU
    compute_prefixsum(prefixSum, total_threads);

#ifdef _DEBUG
    cout << "Count " << (pass ? "=> PASSED)" : "=> FAILED") << endl << endl;
#endif
    unsigned int binCount[4];
    binCount[0] = prefixSum[(total_threads - 1)*BIN_NUM];
    binCount[1] = prefixSum[(total_threads - 1)*BIN_NUM + 1];
    binCount[2] = prefixSum[(total_threads - 1)*BIN_NUM + 2];
    binCount[3] = prefixSum[(total_threads - 1)*BIN_NUM + 3];

    // cmk_radix_bucket(
    // SurfaceIndex input, SurfaceIndex table, SurfaceIndex output,
    // unsigned int bin0_cnt, unsigned int bin1_cnt, unsigned int bin2_cnt,
    // unsigned int bin3_cnt, unsigned int n);
    // set arguments
    // determine even or odd iteration. alternate in and out buffers
    if (even_iteration) {
      cm_result_check(bucket_kernel->SetKernelArg(0, sizeof(SurfaceIndex), input_idx));
      cm_result_check(bucket_kernel->SetKernelArg(2, sizeof(SurfaceIndex), output_idx));
    }
    else {
      cm_result_check(bucket_kernel->SetKernelArg(0, sizeof(SurfaceIndex), output_idx));
      cm_result_check(bucket_kernel->SetKernelArg(2, sizeof(SurfaceIndex), input_idx));
    }

    cm_result_check(bucket_kernel->SetKernelArg(1, sizeof(SurfaceIndex), prefix_idx));
    cm_result_check(bucket_kernel->SetKernelArg(3, sizeof(unsigned int), &binCount[0]));
    cm_result_check(bucket_kernel->SetKernelArg(4, sizeof(unsigned int), &binCount[1]));
    cm_result_check(bucket_kernel->SetKernelArg(5, sizeof(unsigned int), &binCount[2]));
    cm_result_check(bucket_kernel->SetKernelArg(6, sizeof(unsigned int), &binCount[3]));
    cm_result_check(bucket_kernel->SetKernelArg(7, sizeof(unsigned int), &n));

    cm_result_check(cmd_queue->Enqueue(bucket_task, event, thread_space));
    // Waits for the task associated with "sync_event" finishing execution
    // on the GPU.
    cm_result_check(event->WaitForTaskFinished(time_out));
    //
    // validate bin result
    //
#ifdef _DEBUG
    pass = validate_bin(even_iteration ? pActualOutputs : pInputs, binCount, n);
    cout << "Bucket " << (pass ? "=> PASSED" : "=> FAILED") << endl << endl;
    //dumpElems(pActualOutputs, size);
#endif
  //  break;
  }
  clock_t end = clock(); // end timer
  cout << " Sorting Time = " << end - start << " msec " << endl;
  cout << " Prefix Time = " << clock_prefix << " msec " << endl;

  validate_sorted_result(pExpectOutputs, pInputs, size);
  // Flushes the print buffer to stdout.
  // This function call will also clear/reset the print buffer.
  cm_result_check(device->FlushPrintBuffer());

  // Destroys a CmTask object.
  // CmTask will be destroyed when CmDevice is destroyed.
  // Here, the application destroys the CmTask object by itself.
  cm_result_check(device->DestroyTask(cnt_task));
  cm_result_check(device->DestroyTask(bucket_task));

  // Destroy a CmThreadSpace object.
  // CmThreadSpace will be destroyed when CmDevice is destroyed.
  // Here, the application destroys the CmThreadSpace object by itself.
  cm_result_check(device->DestroyThreadSpace(thread_space));
  // Destroys the CmDevice.
  // Also destroys surfaces, kernels, tasks, thread spaces, and queues that
  // were created using this device instance that have not explicitly been
  // destroyed by calling the respective destroy functions.
  cm_result_check(::DestroyCmDevice(device));

  CM_ALIGNED_FREE(pInputs);
  CM_ALIGNED_FREE(pActualOutputs);
  CM_ALIGNED_FREE(prefixSum);
  delete[]pExpectOutputs;

}

int main(int argc, char * argv[])
{

  // This program dispatches several kernels for K2tree utilization:
  //   1. Bits test kernel: Tests bit vector operations on Gen.
  //bitsTest();
  //   2. K2tree construction from matrix: Test the constrution of a K2tree
  //      from a binary matrix. Results are compared vs CPU version
  unsigned k = 2;
  unsigned numThreads = 1;
  unsigned size = 16;
  unsigned p = 3;
  unsigned height = 4;
  //unsigned t_size = 2784; unsigned l_size = 1912; // 128
  //unsigned t_size = 208112; unsigned l_size = 157864; // 1024
  unsigned t_size = 11477624; unsigned l_size = 7709184; // 8192

  //K2treeConstructionTest(size*size, "matrix"+to_string(size)+"x"+to_string(size)+"_"+to_string(p)+".txt");
  //K2treeConstructionTest(size*size, "matrix16x16_original.txt");
  //K2treeConstructionTest(size*size, "matrix"+to_string(size)+"x"+to_string(size)+"_"+to_string(p)+".txt");
  //K2treeConstructionTest(size*size, "matrix"+to_string(size)+"x"+to_string(size)+"_"+to_string(p)+".txt");
  //K2treeQueries(k, size, numThreads, "T_"+to_string(size)+"_"+to_string(p)+"_h_"+to_string(height)+".txt",
  //  "L_"+to_string(size)+"_"+to_string(p)+".txt", "T_rank_"+to_string(size)+"_"+to_string(p)+".txt", height, t_size, l_size);
  //K2treeConstructionFromEdges(32, "");

  //generateMortonNumbers();
  radixSort();
}
